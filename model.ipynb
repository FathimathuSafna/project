{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwFnJsE6vjf8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJr_9dXGpJ05",
        "outputId": "1f1d5b47-411c-4e0a-d33d-9d8fc63027f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gE-Ez1qtyIA"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "kaggle_credentials = json.load(open(\"kaggle.json\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = kaggle_credentials['username']\n",
        "os.environ['KAGGLE_KEY'] = kaggle_credentials['key']"
      ],
      "metadata": {
        "id": "zqZ2Rj8xoE6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d arjuntejaswi/plant-village"
      ],
      "metadata": {
        "id": "e2pdn6AjoHld",
        "outputId": "e989fbcd-1aee-4d50-e0cb-2fcce8d249bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/arjuntejaswi/plant-village\n",
            "License(s): unknown\n",
            "Downloading plant-village.zip to /content\n",
            " 99% 325M/329M [00:02<00:00, 105MB/s]\n",
            "100% 329M/329M [00:02<00:00, 119MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S8YA26iAoK2M",
        "outputId": "2978fe1d-27fc-4312-c404-132a92bddb84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json  plant-village.zip\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile(\"plant-village.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n"
      ],
      "metadata": {
        "id": "RnDMgIpWoOFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size, padding=padding, groups=in_channels)\n",
        "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class FasterCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(FasterCNN, self).__init__()\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            DepthwiseSeparableConv(3, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            DepthwiseSeparableConv(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            DepthwiseSeparableConv(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc_layers(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "R9jzDci5oPhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "00VxhUdbpOj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Define Transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Reduce image size\n",
        "    transforms.RandomResizedCrop(128, scale=(0.7, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n"
      ],
      "metadata": {
        "id": "zeM5afRn4p2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 2: Load Dataset & Split into Train and Test\n",
        "full_dataset = datasets.ImageFolder(root=\"PlantVillage\", transform=train_transform)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_data, test_data = random_split(full_dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "oklTlIY34yCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign correct transformations\n",
        "train_data.dataset.transform = train_transform\n",
        "test_data.dataset.transform = test_transform\n",
        "\n",
        "\n",
        "ttrain_loader = DataLoader(train_data, batch_size=64, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "num_classes = len(full_dataset.classes)  # Get number of classes\n",
        "print(f\"Dataset split: {train_size} train, {test_size} test.\")\n",
        "print(f\"Number of Classes: {num_classes}\")"
      ],
      "metadata": {
        "id": "NzbboEYP5ybw",
        "outputId": "89320477-642d-4a30-a820-ccd9727c97b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset split: 16510 train, 4128 test.\n",
            "Number of Classes: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 3: Define CNN Model (More Layers for Better Accuracy)\n",
        "import torch.nn.functional as F\n",
        "def mixup_data(x, y, alpha=1.0):\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    index = torch.randperm(x.size(0)).to(x.device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ],
      "metadata": {
        "id": "tagX8v9b57eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 4: Initialize Model, Loss & Optimizer\n",
        "model = FasterCNN(num_classes=num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)"
      ],
      "metadata": {
        "id": "oNPtPb255_8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 5: Enable Mixed Precision (FP16 Training)\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "XAEsvLF26W0j",
        "outputId": "43660d7b-bd59-4b48-f7cd-b9050eb055ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-bd0b9110d002>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 6: Train Model\n",
        "num_epochs = 30  # ✅ Reduced epochs (faster training)\n",
        "best_accuracy = 0.0\n",
        "early_stop_count = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():  # ✅ Mixed Precision\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # ✅ Validate Model\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # ✅ Save Best Model\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "        print(\"✔ Model Saved!\")\n",
        "        early_stop_count = 0\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "\n",
        "    if early_stop_count > 5:  # ✅ Early stopping\n",
        "        print(\"🔴 Early Stopping!\")\n",
        "        break\n",
        "\n",
        "# ✅ Step 7: Final Model Evaluation\n",
        "print(f\"✅ Best Accuracy: {best_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "9w2dcNEF6aBj",
        "outputId": "ac662777-fb71-4644-c3ea-828c578d152d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-8ca2526ee4b4>:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # ✅ Mixed Precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 1.0310, Accuracy: 73.57%\n",
            "✔ Model Saved!\n",
            "Epoch [2/30], Loss: 0.6171, Accuracy: 77.42%\n",
            "✔ Model Saved!\n",
            "Epoch [3/30], Loss: 0.4678, Accuracy: 77.64%\n",
            "✔ Model Saved!\n",
            "Epoch [4/30], Loss: 0.3706, Accuracy: 66.11%\n",
            "Epoch [5/30], Loss: 0.3128, Accuracy: 80.50%\n",
            "✔ Model Saved!\n",
            "Epoch [6/30], Loss: 0.2621, Accuracy: 83.33%\n",
            "✔ Model Saved!\n",
            "Epoch [7/30], Loss: 0.2363, Accuracy: 76.94%\n",
            "Epoch [8/30], Loss: 0.2069, Accuracy: 79.09%\n",
            "Epoch [9/30], Loss: 0.1788, Accuracy: 76.79%\n",
            "Epoch [10/30], Loss: 0.1674, Accuracy: 81.40%\n",
            "Epoch [11/30], Loss: 0.1467, Accuracy: 86.70%\n",
            "✔ Model Saved!\n",
            "Epoch [12/30], Loss: 0.1293, Accuracy: 86.99%\n",
            "✔ Model Saved!\n",
            "Epoch [13/30], Loss: 0.1253, Accuracy: 88.95%\n",
            "✔ Model Saved!\n",
            "Epoch [14/30], Loss: 0.1154, Accuracy: 90.87%\n",
            "✔ Model Saved!\n",
            "Epoch [15/30], Loss: 0.1107, Accuracy: 89.66%\n",
            "Epoch [16/30], Loss: 0.1039, Accuracy: 87.60%\n",
            "Epoch [17/30], Loss: 0.0926, Accuracy: 87.89%\n",
            "Epoch [18/30], Loss: 0.0904, Accuracy: 85.83%\n",
            "Epoch [19/30], Loss: 0.0827, Accuracy: 88.61%\n",
            "Epoch [20/30], Loss: 0.0799, Accuracy: 88.28%\n",
            "🔴 Early Stopping!\n",
            "✅ Best Accuracy: 90.87%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('best_model.pth')"
      ],
      "metadata": {
        "id": "8F5t19dl41io",
        "outputId": "bf8bbed3-9b38-4f8d-acdb-539c4db2a21f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4a33df8-4902-4e9e-9bfb-c7dc4d838144\", \"best_model.pth\", 206882)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yyFT0oSC56Dn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}